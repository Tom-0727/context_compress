"""æµ‹è¯• ChunkFilteringStrategy çš„å®Œæ•´æµç¨‹ã€‚"""

from __future__ import annotations

import json
from pathlib import Path

from core.strategies.chunk_filtering import ChunkFilteringStrategy
from utils.text_cleaning import clean_document_text


def main():
    # 1. åŠ è½½ç¼“å­˜çš„æœç´¢ç»“æœ
    cache_file = Path(__file__).parent / "cache" / "tavily_exa_results.json"
    print(f"ğŸ“‚ åŠ è½½æœç´¢ç»“æœ: {cache_file}")

    with open(cache_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    query = data["query_text"]
    raw_results = data["results"]

    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print(f"ğŸ“„ åŸå§‹ç»“æœæ•°: {len(raw_results)}\n")

    # 2. æ¸…æ´—å†…å®¹ï¼ˆåœ¨testä¸­å®Œæˆï¼Œä¸åœ¨ç­–ç•¥å†…éƒ¨ï¼‰
    print("ğŸ§¹ æ¸…æ´—æ–‡æ¡£å†…å®¹...")
    cleaned_results = []

    for item in raw_results:
        url = item["url"]
        content = item.get("content", "")

        # ä½¿ç”¨ clean_document_text æ¸…æ´—
        cleaned = clean_document_text({"content": content})

        if cleaned:
            cleaned_results.append((url, cleaned[:8000]))
            print(f"  âœ“ {url[:50]}... ({len(content)} chars) to ({len(cleaned)} chars)")
        else:
            print(f"  âœ— {url[:50]}... (empty after cleaning)")

    print(f"\nâœ… æ¸…æ´—åæœ‰æ•ˆç»“æœæ•°: {len(cleaned_results)}\n")

    # 3. åˆ›å»ºç­–ç•¥å¹¶å¤„ç†
    print("ğŸ”§ åˆ›å»º ChunkFilteringStrategy å®ä¾‹...")
    strategy = ChunkFilteringStrategy(verbose=True)

    print("âš™ï¸  å¼€å§‹å¤„ç†ï¼ˆåˆ†å— + è¿‡æ»¤ï¼‰...")
    strategy.process(query, cleaned_results)
    breakpoint()

    print(f"ğŸ“¦ chunk_store ä¸­å…±æœ‰ {len(strategy.chunk_store)} ä¸ªchunks")
    print(f"âœ¨ knowledge_base ä¸­ä¿ç•™ {len(strategy.knowledge_base)} ä¸ªç›¸å…³chunks\n")
    breakpoint()

    # 4. è¾“å‡ºç›¸å…³chunk IDs
    print("ğŸ¯ ç›¸å…³çš„ chunk IDs:")
    for chunk_id in strategy.knowledge_base:
        print(f"  - {chunk_id}")

    # 5. è·å–å®Œæ•´ä¸Šä¸‹æ–‡
    print("\nğŸ“ ç”Ÿæˆ checklist context...")
    context = strategy.get_checklist_context()

    print(f"ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
    print(f"ğŸ“Š ä¸Šä¸‹æ–‡é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:\n")
    print("=" * 80)
    print(context[:500])
    print("=" * 80)

    # 6. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_file = Path(__file__).parent / "cache" / "chunk_filtering_result.txt"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"Query: {query}\n")
        f.write(f"Total chunks: {len(strategy.chunk_store)}\n")
        f.write(f"Relevant chunks: {len(strategy.knowledge_base)}\n")
        f.write("\n" + "=" * 80 + "\n\n")
        f.write(context)

    print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    main()
