[框架] DeepSearch 上下文压缩模块 
1. 模块目标与定位
ContextCompacter 是一个有状态 (Stateful) 的服务模块，它内嵌于 DeepSearch Agent 的主工作流中。它的核心职责是：
- 接收 DeepSearch 每次子查询后返回的批量原始网页内容。
- 处理并压缩 这些内容，以两种不同的形态，服务于Agent生命周期的两个关键阶段：
  1. 决策阶段 (Checklist): 为 Checklist Agent 提供一个高度浓缩、低延迟的知识快照，用于判断当前信息是否充足。
  2. 生成阶段 (Summarize): 为最终的报告生成器提供一个信息丰富、忠于原文的上下文，确保最终报告的质量和深度。

2. 核心设计原则
- 状态与接口分离: 模块内部维护所有网页内容的分块(Chunk)和知识(Knowledge)状态，但只对外暴露清晰、稳定的方法接口。DeepSearch Agent 无需关心其内部实现。
- 信息保真度: 除了策略C，所有被压缩的知识必须保留一个指向其最原始文本块 (chunk_id) 的索引，确保在最终生成报告时可以无损地追溯原文。
- 策略可插拔: 模块的核心压缩逻辑应设计为可替换的策略模式，以便我们能够轻松地对架构A、B、C进行独立的实验和评估。

3. 模块架构与组件
a. 内部核心状态 (Internal State):
- chunk_store (Dict[str, str]):
  - 一个全局的键值存储。
  - key: 全局唯一的 chunk_id (例如: hash(url)-chunk_index)。
  - value: 该 chunk 未经处理的原始文本。这是保证信息保真度的唯一事实来源 (Single Source of Truth)。
- knowledge_base (Union[List[Fact], List[str], str]):
  - 一个用于存储压缩后知识的数据库。其具体数据结构由当前采用的压缩策略决定。
  - 策略A下: List[FactObject]，其中 FactObject 包含 {"summary": str, "chunk_ids": List[str], "source_url": str}。
  - 策略B下: List[str]，一个包含所有被认为相关的 chunk_id 的列表。
  - 策略C下: str，一个不断累积更新的、连贯的文本摘要。
b. 核心方法 / 接口 (Public Methods / Interfaces):
- init(self, strategy_name: str):
  - 构造函数，传入一个策略名称（如 'fact_centric', 'chunk_filtering', 'summarization'）来初始化模块。
- process_search_results(self, search_results: List[Tuple[str, str]]):
  - 模块的主入口。根据策略 A, B, C进行不同的处理
  - 如果是策略A，则进行self.chunking_search_results的调用，并进行self.facts_extract的调用
  - 如果是策略B，则进行self.chunking_search_results的调用，并进行self.chunks_extract的调用
  - 如果是策略C，则进行self.pages_summarize的调用
- get_checklist_context(self) -> Union[List[Fact], str]:
  - 供 Checklist Agent 调用。
  - 行为:
    - 策略A下: 返回 knowledge_base 中的 FactObject 列表。
    - 策略B下: 从 chunk_store 中取出 knowledge_base 列表里所有 chunk_id 对应的原文，拼接成一个字符串返回。
    - 策略C下: 返回 knowledge_base 中的摘要字符串。
- reconstruct_report_context(self, relevant_items: List[str] = None) -> str:
  - 供最终报告生成器调用。
  - 行为:
    - 策略A下: 接收 Checklist Agent 筛选出的重要 FactObject 的标识符，找到它们关联的所有 chunk_id，从 chunk_store 中提取原文并结构化地拼接成最终上下文。
    - 策略B/C下: 通常直接返回 get_checklist_context() 的结果，或者可以根据 relevant_items（例如，摘要中的关键句子）做进一步的原文追溯。
C. 内部核心逻辑
- _chunk_and_store(self, search_results: List[Tuple[str, str]]):
  - 对输入进行chunking处理并存储。接收一批 (url, content) 对。
  - 内部流程:
    1. 清洗与分块: 调用已验证的 chunking 流程，将所有 content 切分为 chunks。
    2. 存储: 为每个 chunk 生成唯一的 chunk_id，并存入 self.chunk_store。
- _facts_extract(self, query, chunk_pairs: List[Tuple[str, str]]):
  - 根据设计的prompt进行与query相关的fact-chunk_id对的抽取
- _chunks_extract(self, query, chunk_pairs: List[Tuple[str, str]]):
  - 根据设计的prompt进行与query相关的chunk_id的抽取
- _pages_summarize(self, search_results):
  - 根据设计的prompt对搜索结果内容做压缩

4. 工作流程示例 (Example Workflow)
1. [T=0] DeepSearch Agent 启动，ContextDistiller 被初始化 (strategy='fact_centric')。
2. [T=1] Agent 执行第一次搜索 sub_query_1，获得20个网页结果。
3. [T=2] distiller.process_search_results(results_1) 被调用。模块内部：
  - chunking 完成，chunk_store 存入约320个新 chunk。
  - 策略A被执行，knowledge_base 存入从这20个网页中提取的 FactObject 列表。
4. [T=3] Checklist Agent 调用 distiller.get_checklist_context()，拿到 FactObject 列表。
5. [T=4] Checklist Agent 判断信息不足，生成 sub_query_2。
6. [T=5] Agent 执行第二次搜索，获得另外20个网页结果。
7. [T=6] distiller.process_search_results(results_2) 再次被调用。模块内部：
  - chunk_store 追加 约320个新 chunk。
  - 策略A再次执行，knowledge_base 追加 新提取的 FactObject。
8. [T=7] Checklist Agent 再次调用 distiller.get_checklist_context()，拿到一个更丰富的 FactObject 列表。
9. [T=8] Checklist Agent 判断信息充足，决定进入总结阶段，并标记出最重要的几个 FactObject。
10. [T=9] 报告生成器调用 distiller.reconstruct_report_context(selected_facts)，模块根据 chunk_id 从 chunk_store 中精准地提取出最相关的原文片段，组合成最终的Prompt上下文。
11. [T=10] 生成最终报告。